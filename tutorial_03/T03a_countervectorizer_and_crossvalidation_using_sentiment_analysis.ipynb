{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook is prepared by [Chun-Kit Yeung](https://ckyeungac.com)\n",
    "\n",
    "# Introduction\n",
    "**What did we cover in the last tutorial?**\n",
    "\n",
    "In the last tutorial, we have gone through the following codes to using the naive Bayes classifier in scikit-learn and evaluating the model performance, training accuracy and test accuracy.\n",
    "\n",
    "**What do we cover in this tutorial?**\n",
    "\n",
    "In this tutorial, I will introduce the python packages that are required to complete assignment 1, including\n",
    "+ extract feature from text: `sklearn.feature_extraction.test.CountVectorizer`\n",
    "+ calculating the accuracy score: `sklearn.metrics.accuracy_score`\n",
    "+ performing the 5-fold cross-validation: `sklearn.cross_validation.KFold`\n",
    "\n",
    "As for the `KFold`, I will only cover what it does, but not the exact usage of `KFold` in machine learning. You have to work on your own as it is one of task in the assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.14.1\n",
      "scikit-learn version: 0.19.1\n",
      "matplotlib version: 2.1.2\n"
     ]
    }
   ],
   "source": [
    "# import the required packages\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell the jupyter notebook that plot the diagram directly in the output\n",
    "%matplotlib inline \n",
    "    \n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sklearn.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)\n",
    "\n",
    "SEP = '='*30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a toy dataset that include a list of tuples `(<sentence>, <sentiment_label>)` to have a taste in handling the text data.\n",
    "\n",
    "`<sentence>` is a english sentence. Usually, it contains some of the positive/negative information/emotion. So, one of the popular task in machine learning is sentiment analysis in which machine learinng experts build models to predict the emotion of a sentence. In this toy example, the `<sentiment>` label is simply 0 or 1, indicating a negative or positive emotion is observed in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (<sentence>, <sentiment_label>)\n",
    "# sentiment_label=1 means positive, 0 means negative.\n",
    "toy_sentiment_dataset = [\n",
    "    ('Today I am so happy and you are so happy.', 1),\n",
    "    ('Happy is so important and you are so important too', 1),\n",
    "    ('you look so great and happy!', 1),\n",
    "    ('Don\\'t be so sad, dude', 0),\n",
    "    ('Machine learning is difficult', 0),\n",
    "    ('COMP 4211 is the goodest', 1),\n",
    "    ('James is so good', 1),\n",
    "    ('Kit is so sad', 0),\n",
    "]\n",
    "\n",
    "sentences = [data[0] for data in toy_sentiment_dataset]\n",
    "sentiment = [data[1] for data in toy_sentiment_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert text to vector using [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)**\n",
    "\n",
    "It is a handy package to convert a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CountVectorizer to perform the text vectorization\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what is it look like in vector representation\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what is the content if we convert the vector back to words. (Not sentence!)\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Building toy sentiment prediction model using [`artificial neural network`](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MLPClassifier to build and train the ANN\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the artificial neural network using the [`accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) provided by scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use accuracy_score to calculate the accuracy\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross-validation\n",
    "In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples, so-called **folds**. Of the k folds, **a single fold is retained as the test set**, and **the remaining k - 1 subsamples are used as training set**. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data.\n",
    "\n",
    "In scikit-learn, it provides a handy package called [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) to facilitate k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KFold to get the train and test index\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
