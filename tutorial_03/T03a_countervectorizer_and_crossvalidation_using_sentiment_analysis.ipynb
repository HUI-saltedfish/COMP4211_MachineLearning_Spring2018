{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook is prepared by [Chun-Kit Yeung](https://ckyeungac.com)\n",
    "\n",
    "# Introduction\n",
    "**What did we cover in the last tutorial?**\n",
    "\n",
    "In the last tutorial, we have gone through the following codes to using the naive Bayes classifier in scikit-learn and evaluating the model performance, training accuracy and test accuracy.\n",
    "\n",
    "**What do we cover in this tutorial?**\n",
    "\n",
    "In this tutorial, I will introduce the python packages that are required to complete assignment 1, including\n",
    "+ extract feature from text: `sklearn.feature_extraction.test.CountVectorizer`\n",
    "+ calculating the accuracy score: `sklearn.metrics.accuracy_score`\n",
    "+ performing the 5-fold cross-validation: `sklearn.cross_validation.KFold`\n",
    "\n",
    "As for the `KFold`, I will only cover what it does, but not the exact usage of `KFold` in machine learning. You have to work on your own as it is one of task in the assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.11.3\n",
      "scikit-learn version: 0.18.1\n",
      "matplotlib version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "# import the required packages\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell the jupyter notebook that plot the diagram directly in the output\n",
    "%matplotlib inline \n",
    "    \n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sklearn.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)\n",
    "\n",
    "SEP = '='*30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a toy dataset that include a list of tuples `(<sentence>, <sentiment_label>)` to have a taste in handling the text data.\n",
    "\n",
    "`<sentence>` is a english sentence. Usually, it contains some of the positive/negative information/emotion. So, one of the popular task in machine learning is sentiment analysis in which machine learinng experts build models to predict the emotion of a sentence. In this toy example, the `<sentiment>` label is simply 0 or 1, indicating a negative or positive emotion is observed in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (<sentence>, <sentiment_label>)\n",
    "# sentiment_label=1 means positive, 0 means negative.\n",
    "toy_sentiment_dataset = [\n",
    "    ('Today I am so happy and you are so happy.', 1),\n",
    "    ('Happy is so important and you are so important too', 1),\n",
    "    ('you look so great and happy!', 1),\n",
    "    ('Don\\'t be so sad, dude', 0),\n",
    "    ('Machine learning is difficult', 0),\n",
    "    ('COMP 4211 is the goodest', 1),\n",
    "    ('James is so good', 1),\n",
    "    ('Kit is so sad', 0),\n",
    "]\n",
    "\n",
    "sentences = [data[0] for data in toy_sentiment_dataset]\n",
    "sentiment = [data[1] for data in toy_sentiment_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert text to vector using [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)**\n",
    "\n",
    "It is a handy package to convert a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use CountVectorizer to perform the text vectorization\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# See what is it look like in vector representation\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['4211', 'comp', 'goodest'], \n",
      "      dtype='<U9')]\n"
     ]
    }
   ],
   "source": [
    "# See what is the content if we convert the vector back to words. (Not sentence!)\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Building toy sentiment prediction model using [`artificial neural network`](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_23/lib/python3.4/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use MLPClassifier to build and train the ANN\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the artificial neural network using the [`accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) provided by scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "# Use accuracy_score to calculate the accuracy\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross-validation\n",
    "In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples, so-called **folds**. Of the k folds, **a single fold is retained as the test set**, and **the remaining k - 1 subsamples are used as training set**. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data.\n",
    "\n",
    "In scikit-learn, it provides a handy package called [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) to facilitate k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "==============================\n",
      "Training index: [2 3 4 5 6 7 8 9]\n",
      "Test index: [0 1]\n",
      "============================== \n",
      "\n",
      "Fold 2\n",
      "==============================\n",
      "Training index: [0 1 4 5 6 7 8 9]\n",
      "Test index: [2 3]\n",
      "============================== \n",
      "\n",
      "Fold 3\n",
      "==============================\n",
      "Training index: [0 1 2 3 6 7 8 9]\n",
      "Test index: [4 5]\n",
      "============================== \n",
      "\n",
      "Fold 4\n",
      "==============================\n",
      "Training index: [0 1 2 3 4 5 8 9]\n",
      "Test index: [6 7]\n",
      "============================== \n",
      "\n",
      "Fold 5\n",
      "==============================\n",
      "Training index: [0 1 2 3 4 5 6 7]\n",
      "Test index: [8 9]\n",
      "============================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use KFold to get the train and test index\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
