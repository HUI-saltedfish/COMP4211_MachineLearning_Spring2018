{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This jupyter notebook is prepared by [Chun-Kit Yeung](https://ckyeungac.com)\n",
    "\n",
    "# Introduction\n",
    "**What do we cover in this tutorial?**\n",
    "\n",
    "In this tutorial, we will use the Perceptron and ADALINE to tackle the iris classification problem introduced in tutorial 2. However, since the iris dataset has 3 labels while both perceptron and ADALINE are a binary classifier, we will only use the first two classes in the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target[:100] # the first 100 elements are either 0, or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the target data (first 100 data points) with slicing\n",
    "X_iris = iris.data[:100]\n",
    "y_iris = iris.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spliting the data into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Perceptron from sklearn\n",
    "Here, we first train a perceptron (documentation can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)) provided by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the Perceptron library from sklearn and train the perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "# import the accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the perceptron\n",
    "clf = Perceptron(fit_intercept=True, eta0=0.5) # eta0 is the learning rate\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ADALINE from sklearn\n",
    "**Unfortunately, there is no ADALINE in scikit-learn.** Yet, ADALINE is simply just a special case of artificial neural network with only 1 input layer and 1 output layer. As an altenative, we simply consider **a multi-layer perceptron (MLP) with no hidden layer** to be the ADALINE (even thought they are not exactly the same.)\n",
    "\n",
    "Yet, so as to align with the course materials, I implemented a class called AdalineSGD (available in ''*DIY: Build your own ADALINE with stochastic gradient descent*'') for you to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(), # empty tuple -> no hidden layer used.\n",
    "    activation='tanh', # tanh return a value from [-1, 1], similar to step function\n",
    "    solver='sgd', # stochastic gradient descent\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY: Build your own Preceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron2(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    eta: float \n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter: int\n",
    "        Number of epochs, i.e. number of iteration passes over the training dataset.\n",
    "        \n",
    "    Attributes\n",
    "    ------------\n",
    "    w_: 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_: list\n",
    "        Number of misclassifications in every epoch.\n",
    "    random_state : int\n",
    "        The seed of the pseudo random number generator.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, eta=0.01, n_iter=100, random_state=1):\n",
    "        \"\"\"Initialize the class variables\"\"\"\n",
    "        # Todo\n",
    "        pass\n",
    "            \n",
    "    def _initialize_weights(self, m):\n",
    "        \"\"\"Randomly initialize weights\"\"\"\n",
    "        # Todo\n",
    "        pass\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        # Todo\n",
    "        pass\n",
    "    \n",
    "    def _predict(self, X):\n",
    "        \"\"\"Return class label after unit step for internal usage.\"\"\"\n",
    "        # Todo\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step for external usage.\"\"\"\n",
    "        # Todo\n",
    "        pass\n",
    "                \n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"Apply Perceptron learning rule to update the weights for a single sample.\"\"\"\n",
    "        # Todo\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        # Todo:\n",
    "        # initialize the weight\n",
    "        # make a copy of y: y_\n",
    "        # convert the value of 0 to -1 in y_\n",
    "        # update the weight\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron2()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY: Build your own ADALINE with stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "\n",
    "class AdalineSGD(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "        Learning rate\n",
    "    n_iter : int\n",
    "        Number of iteration passes over the training dataset.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_ : list\n",
    "        Number of misclassifications in every epoch.\n",
    "    shuffle : bool (default: True)\n",
    "        Shuffles training data every epoch if True to prevent cycles.\n",
    "    random_state : int\n",
    "        Set random state for shuffling and initializing the weights.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, shuffle=True, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.w_initialized = False\n",
    "        self.shuffle = shuffle\n",
    "        if random_state:\n",
    "            seed(random_state)\n",
    "            \n",
    "    def _shuffle(self, X, y):\n",
    "        \"\"\"Shuffle training data\"\"\"\n",
    "        r = np.random.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "    \n",
    "    def _initialize_weights(self, m):\n",
    "        \"\"\"Randomly initialize weights\"\"\"\n",
    "        self.w_ = np.random.normal(loc=0.0, scale=0.01, size=1 + m)\n",
    "        self.w_initialized = True\n",
    "            \n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"Apply Adaline learning rule to update the weights for a single sample.\"\"\"\n",
    "        output = self.activation(xi)\n",
    "        error = (target - output)\n",
    "        self.w_[1:] += self.eta * xi.dot(error)\n",
    "        self.w_[0] += self.eta * error\n",
    "        cost = 0.5 * error**2\n",
    "        return cost\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0] \n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return self.net_input(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(X) >= 0.0, 1, 0)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        # initialize the weight\n",
    "        self._initialize_weights(X.shape[1])\n",
    "        \n",
    "        # make a copy of y: y_\n",
    "        y_ = np.copy(y) # e.g. it is np.array([1,1,0,1,0,0,1])\n",
    "        \n",
    "        #convert the value of 0 to -1 in y_\n",
    "        y_[y_==0] = -1 # e.g. it is now np.array([1,1,-1,1,-1,-1,1])\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            # shuffle the data if required\n",
    "            if self.shuffle:\n",
    "                X, y_ = self._shuffle(X, y_)\n",
    "            \n",
    "            # update the weight sample by sample\n",
    "            for xi, target in zip(X, y_):\n",
    "                self._update_weights(xi, target)\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdalineSGD()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what is the learnt weight\n",
    "clf.w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
